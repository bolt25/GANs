{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#hyperparameters\n",
    "batchsize=1 #batch-size of 1\n",
    "imgsize=720 #image of size (128,128)\n",
    "\n",
    "#creating transformations so that the image is ready to be fed to the neural network\n",
    "transform=transforms.Compose([transforms.Resize(imgsize),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) # Applying transformation(resizing,tensor conversion and normalization) to the image  \n",
    "\n",
    "#loading the dataset\n",
    "dataset=dsets.ImageFolder(root='mydata',transform=transform)\n",
    "dataloader=torch.utils.data.DataLoader(dataset,batch_size=batchsize,shuffle=True,num_workers=4) #Dataloader helps is to load data in specific batch size and whether we want to shuffle it or not and num_workers=-1 means it uses all the parallel processes available\n",
    "\n",
    "print('Dataloader executed')\n",
    "#GANs use a different type of weight initialization called Xavier's Initialization\n",
    "def weights(network):\n",
    "\tclassname=network.__class__.__name__ # this line searches for the name of the class in the network defination\n",
    "\tif classname.find('Conv') !=-1: #this line finds the occurance of the string 'Conv' in the network function's defination and if the string 'Conv' is present then it activates the if loop\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnetwork.weight.normal_(0.0,0.02)\n",
    "\telif classname.find('BatchNorm')!=-1: #similar operation as above\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnetwork.weight.data.normal_(1.0,0.02)\n",
    "\t\t# network.bias.data.fill_(0)\n",
    "# Defining the generator network\n",
    "\n",
    "class generator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(generator,self).__init__() # this line passes all the goodness of nn.module in the generator class that we defined\n",
    "#(1,1)  ------------------> size of output image    \n",
    "\t\tself.main=nn.Sequential(nn.ConvTranspose2d(100,1024,4,1,0,bias=False), #100 is the input noise vector, 1024 are the new feature maps,4 is the size of kernel(4,4),1 is the stride of the kernel,0 is the padding and bias is set to false\n",
    "\t\t\tnn.ReLU(True), #to introduce non-linearity\n",
    "\t\t\tnn.BatchNorm2d(1024), #normalizing all the new feature maps\n",
    "# (4,4)  ------------------> size of output image\n",
    "\t\t\tnn.ConvTranspose2d(1024,512,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(512),\n",
    "# (8,8)  ------------------> size of output image\n",
    "\t\t\tnn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "#(16,16)  ------------------> size of output image\n",
    "\t\t\tnn.ConvTranspose2d(256,128,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(128),\n",
    "#(32,32)  ------------------> size of output image\n",
    "\t\t\tnn.ConvTranspose2d(128,64,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(64),\n",
    "#(64,64)  ------------------> size of output image\n",
    "\t\t\tnn.ConvTranspose2d(64,32,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(32),\n",
    "# (128,128)  ------------------> size of output image\n",
    "\t\t\tnn.ConvTranspose2d(32,16,3,3,12,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(16),\n",
    "#(360,360)  ------------------> size of output image\n",
    "\t\t\tnn.ConvTranspose2d(16,3,4,2,1,bias=False),\n",
    "#(720,720)  ------------------> size of output image\n",
    "\t\t\tnn.Tanh() #Tanh is selected here because the dataset has values between -1 and 1 , also Tanh is bounded, this bounded and symmetrical nature of the function helps the model to learn faster \n",
    "\t\t\t)\n",
    "\tdef forward(self,x):\n",
    "\t\toutput=self.main(x)\n",
    "\t\treturn output\n",
    "netG=generator()\n",
    "netG.cuda()\n",
    "netG.apply(weights) #applying weights initizlization function on the generator function\n",
    "\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(discriminator,self).__init__() #to activate inheritance\n",
    "\t\tself.main=nn.Sequential(\n",
    "\t\t\tnn.Conv2d(3,64,4,2,1,bias=False),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(64,128,4,2,1,bias=False),\n",
    "\t\t\tnn.BatchNorm2d(128),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(128,256,4,2,1,bias=False),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(256,512,4,2,1,bias=False),\n",
    "\t\t\tnn.BatchNorm2d(512),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(512,1024,4,2,1,bias=False),\n",
    "\t\t\tnn.BatchNorm2d(1024),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(1024,1,4,1,0,bias=False),\n",
    "\t\t\tnn.Sigmoid()\n",
    "\t\t\t)\n",
    "\tdef forward(self,x):\n",
    "\t\toutput=self.main(x)\n",
    "\t\treturn output.view(-1) # .view(-1) is used to reshape the convouled image and flatten it along a single axis.\n",
    "\n",
    "print('Networks defined')\n",
    "netD=discriminator()\n",
    "netD.cuda()\n",
    "netD.apply(weights) #applying weights initizlization function on the generator function\n",
    "\n",
    "run=500 ### number of epochs\n",
    "\n",
    "\n",
    "\n",
    "###### TRAINING THE GANs ########\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD=optim.Adam(netD.parameters(),lr=0.001,betas=(0.5,0.999)) #the value of betas is selected from experimentation\n",
    "optimizerG=optim.Adam(netG.parameters(),lr=0.001,betas=(0.5,0.999))\n",
    "err_dis=[]\n",
    "err_gen=[]\n",
    "\n",
    "\n",
    "print('Loop starting now')\n",
    "\n",
    "\n",
    "for epoch in range(run):\t\n",
    "\tfor i,data in enumerate(dataloader,0): #0 in the enumerate parenthesis is just the starting value we want 'i' to take.\n",
    "\t\toptimizerD.zero_grad() #clearing gradient buffers and setting it to zero for every new batch\n",
    "\n",
    "\n",
    "\n",
    "\t\t###Training the discriminator network on real images\n",
    "\n",
    "\t\timages,_=data #_ here holds the labels of the images. As we dont want the labels here we just throw it away\n",
    "\t\treal=Variable(images.cuda()) #to compute gradients, we need to wrap the image with a Variable class\n",
    "\t\toutput=netD(real) #computing the outputs through discriminator which will be a number between 0 and 1 giving probablity of image being real or fake\n",
    "\t\treal_targets=Variable(torch.ones(output.size()[0]).cuda()) \n",
    "\t\terror_real=criterion(output,real_targets) #calculating the error for real images and their output given by our discriminator network\n",
    "\n",
    "\t\t###Training the network on fake images\n",
    "\t\tnoise=Variable(torch.randn(real.size()[0],100,1,1).cuda()) #this line can be interpreted like a matrix which has real.size()[0] number of rows and 100 number of columns(technically feature maps) and each column has a 1x1 array\n",
    "\t\tfake_output=netG(noise)  #generator uses this noise vector to generate a mini-batch of fakeimages\n",
    "\t\toutput=netD(fake_output.detach()) #the fake_output is a torch variable and it contains the data as well as the gradients, but we dont want this gradients so we will only use the data and for that we use .detach() method\n",
    "\t\tfake_target=Variable(torch.zeros(output.size()[0]).cuda())#instantiating the fake target as 0s\n",
    "\t\terror_fake=criterion(output,fake_target) #calculating the error of fake images with wrt their output\n",
    "\n",
    "\t\terror_total=error_real+error_fake\n",
    "\t\terror_total.backward() #this line back-propagates the error \n",
    "\t\toptimizerD.step()      #this line updates the parameters of netD\n",
    "\n",
    "\t\t##Training the generator\n",
    "\t\toptimizerG.zero_grad() #initializing the gradients of generaotr neural net\n",
    "\t\toutput=netD(fake_output) #notice here we didnt use .detach() because we want to update the weights of generator unlike previously where we were updating the weights of discriminator, because the fake_output is generated by generator and not discriminator\n",
    "\t\ttarget=Variable(torch.ones(output.size()[0]).cuda()) #here we defined targets as 1s because we want the generator to generate near perfect images which the discriminator should predict as real( or target =1) \n",
    "\t\terror_gen=criterion(output,target)\n",
    "\t\terror_gen.backward()\n",
    "\t\toptimizerG.step()\n",
    "\t\tprint('[%d/%d][%d/%d] Loss_D: %.4f----Loss_G: %.4f' % (epoch, run, i, len(dataloader), error_total.data, error_gen.data))\n",
    "\t\tif i%1000==0:\n",
    "\t\t\tvutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize = True)\n",
    "\t\t\tfake = netG(noise)\n",
    "\t\t\tvutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results\", epoch), normalize = True)\n",
    "\terr_dis.append(torch.sum(error_total))\n",
    "\terr_gen.append(torch.sum(error_gen))\n",
    "\n",
    "print('Training Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(run),err_dis,label='Discriminator')\n",
    "plt.plot(range(run),err_gen,label='Generator')\n",
    "plt.legend()\n",
    "plt.title('Training Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('loss_trend.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netD,'Discriminator network 1')\n",
    "torch.save(netG,'Generator network 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=torch.load('Discriminator network') #use this line to save model in variable 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
